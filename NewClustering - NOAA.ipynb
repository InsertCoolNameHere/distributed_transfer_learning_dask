{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "civilian-candy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "from sklearn import ensemble\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-engagement",
   "metadata": {},
   "source": [
    "<h3><u>CONSTANTS AND HELPER FUNSTIONS</u></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beneficial-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_collection = \"noaa_nam_2\"\n",
    "mongo_url = \"mongodb://lattice-100:27018/\"\n",
    "mongo_db_name = \"sustaindb\"\n",
    "query_fild = \"gis_join\"\n",
    "sample_percent = 0.1\n",
    "train_test = 0.8\n",
    "feature_importance_percentage = 98\n",
    "exhaustive_sample_percent = 0.0001\n",
    "\n",
    "\n",
    "training_labels = [\"mean_sea_level_pressure_pascal\",\n",
    "                   \"surface_pressure_surface_level_pascal\",\n",
    "                   \"10_metre_u_wind_component_meters_per_second\",\n",
    "                   \"10_metre_v_wind_component_meters_per_second\",\n",
    "                   \"soil_temperature_kelvin\"]\n",
    "\n",
    "target_labels = [\"pressure_pascal\"]\n",
    "\n",
    "# QUERY-RELATED\n",
    "sustainclient = pymongo.MongoClient(mongo_url)\n",
    "sustain_db = sustainclient[mongo_db_name]\n",
    "\n",
    "# QUERY projection\n",
    "client_projection = {}\n",
    "for val in training_labels:\n",
    "    client_projection[val] = 1\n",
    "for val in target_labels:\n",
    "    client_projection[val] = 1\n",
    "    \n",
    "    \n",
    "def fancy_logging(msg, unique_id=\"\"):\n",
    "    print(unique_id, \":\", \"====================================\")\n",
    "    print(unique_id, \":\", msg, \": TIME: \",time())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-pharmacy",
   "metadata": {},
   "source": [
    "<h3><u>DATA FETCH</u></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "controlled-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTUAL QUERYING\n",
    "def query_sustaindb(query_gisjoin):\n",
    "\n",
    "    sustain_collection = sustain_db[query_collection]\n",
    "    client_query = {query_fild: query_gisjoin}\n",
    "\n",
    "    start_time = time()\n",
    "    query_results = list(sustain_collection.find(client_query, client_projection))\n",
    "    \n",
    "    return list(query_results)\n",
    "\n",
    "def queryall_sustaindb():\n",
    "\n",
    "    sustain_collection = sustain_db[query_collection]\n",
    "    client_query = {}\n",
    "\n",
    "    start_time = time()\n",
    "    query_results = list(sustain_collection.find(client_query, client_projection))\n",
    "    \n",
    "    return list(query_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "metropolitan-assignment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:  7431587\n"
     ]
    }
   ],
   "source": [
    "#df = query_sustaindb('G3701310')\n",
    "df = queryall_sustaindb()\n",
    "print(\"1: \", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-receptor",
   "metadata": {},
   "source": [
    "<h3><u>DATA SAMPLING</u></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "built-medium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sampling(query_results, exhaustive, sample_percent=1):\n",
    "    if exhaustive:\n",
    "        all_data = query_results\n",
    "    else:\n",
    "        data_size = int(len(query_results) * sample_percent)\n",
    "        all_data = sample(query_results, data_size)\n",
    "\n",
    "    return pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mysterious-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIKI\n",
    "sampled_df = data_sampling(df, False, exhaustive_sample_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "liberal-trouble",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(743, 5) (743, 1)\n"
     ]
    }
   ],
   "source": [
    "Y = sampled_df.loc[:,target_labels]\n",
    "X = sampled_df.loc[:, training_labels]\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-parallel",
   "metadata": {},
   "source": [
    "<h3><u>DATA SPLITTING INTO TRAING AND VALIDATION</u></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "differential-porter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def data_partitioning(query_results, exhaustive, sample_percent=1):\\n    if exhaustive:\\n        all_data = query_results\\n    else:\\n        data_size = int(len(query_results) * sample_percent)\\n        all_data = sample(query_results, data_size)\\n\\n    msk = np.random.rand(len(all_data)) < train_test\\n\\n    all_data = pd.DataFrame(all_data)\\n    training_data = all_data[msk]\\n    val_data = all_data[~msk]\\n    return (pd.DataFrame(training_data), pd.DataFrame(val_data))'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def data_partitioning(query_results, exhaustive, sample_percent=1):\n",
    "    if exhaustive:\n",
    "        all_data = query_results\n",
    "    else:\n",
    "        data_size = int(len(query_results) * sample_percent)\n",
    "        all_data = sample(query_results, data_size)\n",
    "\n",
    "    msk = np.random.rand(len(all_data)) < train_test\n",
    "\n",
    "    all_data = pd.DataFrame(all_data)\n",
    "    training_data = all_data[msk]\n",
    "    val_data = all_data[~msk]\n",
    "    return (pd.DataFrame(training_data), pd.DataFrame(val_data))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "alien-geometry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(594, 5) (149, 5) (594, 1) (149, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-community",
   "metadata": {},
   "source": [
    "<h3><u>MODELING</u></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "turned-essex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'parameters = [ {\\'n_estimators\\': 500, \\'max_depth\\': 2, \\'min_samples_split\\': 20},\\n                {\\'n_estimators\\': 300, \\'max_depth\\': 3, \\'min_samples_split\\': 50},\\n              {\\'n_estimators\\': 500, \\'max_depth\\': 3, \\'min_samples_split\\': 20},\\n              {\\'n_estimators\\': 600, \\'max_depth\\': 3, \\'min_samples_split\\': 15}]\\n    \\nfor params in parameters:\\n    print(\"PARAMETERS:\",params)\\n    count = 0\\n    error = 0\\n    for i in range(0,5):\\n        print(\"ROUND:\",i)\\n        clf = ensemble.RandomForestRegressor(**params)\\n        clf.fit(X_train, pd.Series.ravel(y_train))\\n\\n        rmse = sqrt(mean_squared_error(pd.Series.ravel(y_test), clf.predict(X_test)))\\n        print(rmse)\\n        error = error + rmse\\n\\n        feature_importance = clf.feature_importances_\\n        feature_importance = 100.0 * (feature_importance / feature_importance.sum())\\n        sorted_idx = np.argsort(feature_importance)\\n        count = count+1\\n        print(np.flip(sorted_idx), np.flip(feature_importance[sorted_idx]))\\n    \\n    print(\"===============================================================\")\\n\\n    print(\"AVG RMSE:\",(error/count))'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''parameters = [ {'n_estimators': 500, 'max_depth': 2, 'min_samples_split': 20},\n",
    "                {'n_estimators': 300, 'max_depth': 3, 'min_samples_split': 50},\n",
    "              {'n_estimators': 500, 'max_depth': 3, 'min_samples_split': 20},\n",
    "              {'n_estimators': 600, 'max_depth': 3, 'min_samples_split': 15}]\n",
    "    \n",
    "for params in parameters:\n",
    "    print(\"PARAMETERS:\",params)\n",
    "    count = 0\n",
    "    error = 0\n",
    "    for i in range(0,5):\n",
    "        print(\"ROUND:\",i)\n",
    "        clf = ensemble.RandomForestRegressor(**params)\n",
    "        clf.fit(X_train, pd.Series.ravel(y_train))\n",
    "\n",
    "        rmse = sqrt(mean_squared_error(pd.Series.ravel(y_test), clf.predict(X_test)))\n",
    "        print(rmse)\n",
    "        error = error + rmse\n",
    "\n",
    "        feature_importance = clf.feature_importances_\n",
    "        feature_importance = 100.0 * (feature_importance / feature_importance.sum())\n",
    "        sorted_idx = np.argsort(feature_importance)\n",
    "        count = count+1\n",
    "        print(np.flip(sorted_idx), np.flip(feature_importance[sorted_idx]))\n",
    "    \n",
    "    print(\"===============================================================\")\n",
    "\n",
    "    print(\"AVG RMSE:\",(error/count))'''\n",
    "\n",
    "# BETTER ALTERNATIVE BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abstract-thousand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 3\n",
      "n_required_iterations: 3\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 150\n",
      "max_resources_: 600\n",
      "aggressive_elimination: False\n",
      "factor: 2\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 6\n",
      "n_resources: 150\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END max_depth=2, min_samples_split=15, n_estimators=150;, score=(train=0.250, test=0.113) total time=   0.4s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=15, n_estimators=150;, score=(train=0.240, test=0.138) total time=   0.3s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=15, n_estimators=150;, score=(train=0.243, test=0.085) total time=   0.3s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=15, n_estimators=150;, score=(train=0.220, test=0.274) total time=   0.3s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=15, n_estimators=150;, score=(train=0.208, test=0.125) total time=   0.3s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=20, n_estimators=150;, score=(train=0.250, test=0.113) total time=   0.3s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=20, n_estimators=150;, score=(train=0.238, test=0.139) total time=   0.3s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=20, n_estimators=150;, score=(train=0.242, test=0.085) total time=   0.3s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=20, n_estimators=150;, score=(train=0.220, test=0.274) total time=   0.6s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=20, n_estimators=150;, score=(train=0.204, test=0.127) total time=   0.3s\n",
      "[CV 1/5] END max_depth=2, min_samples_split=50, n_estimators=150;, score=(train=0.202, test=0.114) total time=   0.3s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=50, n_estimators=150;, score=(train=0.194, test=0.129) total time=   0.3s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=50, n_estimators=150;, score=(train=0.209, test=0.016) total time=   0.3s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=50, n_estimators=150;, score=(train=0.189, test=0.237) total time=   0.3s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=50, n_estimators=150;, score=(train=0.187, test=0.123) total time=   0.3s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=15, n_estimators=150;, score=(train=0.318, test=0.116) total time=   0.3s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=15, n_estimators=150;, score=(train=0.327, test=0.140) total time=   0.3s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=15, n_estimators=150;, score=(train=0.309, test=0.123) total time=   0.3s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=15, n_estimators=150;, score=(train=0.300, test=0.314) total time=   0.3s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=15, n_estimators=150;, score=(train=0.282, test=0.143) total time=   0.3s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=20, n_estimators=150;, score=(train=0.311, test=0.117) total time=   0.3s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=20, n_estimators=150;, score=(train=0.317, test=0.145) total time=   0.4s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=20, n_estimators=150;, score=(train=0.304, test=0.119) total time=   0.3s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=20, n_estimators=150;, score=(train=0.294, test=0.310) total time=   0.4s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=20, n_estimators=150;, score=(train=0.271, test=0.145) total time=   0.3s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=50, n_estimators=150;, score=(train=0.245, test=0.119) total time=   0.3s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=50, n_estimators=150;, score=(train=0.248, test=0.142) total time=   0.3s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=50, n_estimators=150;, score=(train=0.252, test=0.032) total time=   0.3s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=50, n_estimators=150;, score=(train=0.237, test=0.256) total time=   0.3s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=50, n_estimators=150;, score=(train=0.234, test=0.129) total time=   0.3s\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 3\n",
      "n_resources: 300\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END max_depth=2, min_samples_split=20, n_estimators=300;, score=(train=0.251, test=0.115) total time=   0.6s\n",
      "[CV 2/5] END max_depth=2, min_samples_split=20, n_estimators=300;, score=(train=0.242, test=0.134) total time=   0.6s\n",
      "[CV 3/5] END max_depth=2, min_samples_split=20, n_estimators=300;, score=(train=0.244, test=0.088) total time=   0.5s\n",
      "[CV 4/5] END max_depth=2, min_samples_split=20, n_estimators=300;, score=(train=0.220, test=0.273) total time=   0.5s\n",
      "[CV 5/5] END max_depth=2, min_samples_split=20, n_estimators=300;, score=(train=0.206, test=0.130) total time=   0.6s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=20, n_estimators=300;, score=(train=0.313, test=0.116) total time=   0.6s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=20, n_estimators=300;, score=(train=0.320, test=0.144) total time=   0.6s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=20, n_estimators=300;, score=(train=0.307, test=0.124) total time=   0.6s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=20, n_estimators=300;, score=(train=0.293, test=0.307) total time=   0.6s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=20, n_estimators=300;, score=(train=0.271, test=0.151) total time=   0.6s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=15, n_estimators=300;, score=(train=0.321, test=0.117) total time=   0.6s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=15, n_estimators=300;, score=(train=0.330, test=0.141) total time=   0.6s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=15, n_estimators=300;, score=(train=0.313, test=0.128) total time=   0.6s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=15, n_estimators=300;, score=(train=0.300, test=0.313) total time=   0.6s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=15, n_estimators=300;, score=(train=0.282, test=0.149) total time=   0.6s\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 2\n",
      "n_resources: 600\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5] END max_depth=3, min_samples_split=20, n_estimators=600;, score=(train=0.313, test=0.119) total time=   1.1s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=20, n_estimators=600;, score=(train=0.323, test=0.145) total time=   1.1s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=20, n_estimators=600;, score=(train=0.309, test=0.126) total time=   1.2s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=20, n_estimators=600;, score=(train=0.297, test=0.300) total time=   1.2s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=20, n_estimators=600;, score=(train=0.270, test=0.150) total time=   1.2s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=15, n_estimators=600;, score=(train=0.321, test=0.119) total time=   1.2s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=15, n_estimators=600;, score=(train=0.333, test=0.142) total time=   1.2s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=15, n_estimators=600;, score=(train=0.314, test=0.128) total time=   1.1s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=15, n_estimators=600;, score=(train=0.304, test=0.306) total time=   1.2s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=15, n_estimators=600;, score=(train=0.282, test=0.147) total time=   1.2s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "param_grid = {'max_depth': [2, 3], 'min_samples_split': [15, 20, 50]}\n",
    "base_est = ensemble.RandomForestRegressor(random_state=0)\n",
    "sh = HalvingGridSearchCV(base_est, param_grid, cv=5, verbose=3, \n",
    "                         factor=2, resource='n_estimators', max_resources=600).fit(X, pd.Series.ravel(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "agricultural-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE BEST MODEL\n",
    "clf_best = sh.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "settled-warning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3874.244869769391"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(pd.Series.ravel(y_test), clf_best.predict(X_test)))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-sarah",
   "metadata": {},
   "source": [
    "<h3><u>EXTRACT TOP FEATURES</u></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "diagnostic-device",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 4 1 2 3] [37.80652075 34.2716431  13.82809946  7.27583804  6.81789865]\n",
      "[0 4 1 2 3]\n",
      "[37.80652075 34.2716431  13.82809946  7.27583804  6.81789865]\n"
     ]
    }
   ],
   "source": [
    "feature_importance = clf_best.feature_importances_\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.sum())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "print(np.flip(sorted_idx), np.flip(feature_importance[sorted_idx]))\n",
    "\n",
    "feature_importance = np.flip(feature_importance[sorted_idx])\n",
    "sorted_idx=np.flip(sorted_idx)\n",
    "\n",
    "print(sorted_idx)\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-israeli",
   "metadata": {},
   "source": [
    "<h3><u>FIND N FOR WHICH IMPORTANCE % > feature-importance-percentage</u></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "apparent-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cumulative(lists, val_max):\n",
    "    cu_list = []\n",
    "    length = len(lists)\n",
    "    cu_list = [sum(lists[0:x:1]) for x in range(1, length+1)]\n",
    "    \n",
    "    print(cu_list)\n",
    "    res = next(x for x, val in enumerate(cu_list)\n",
    "                                  if val > val_max)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "convenient-footage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37.806520748922814, 72.07816384533966, 85.9062633089815, 93.1821013529657, 99.99999999999999]\n",
      "LAST INDEX:  4\n"
     ]
    }
   ],
   "source": [
    "cut_off_indx = find_cumulative(feature_importance, feature_importance_percentage)\n",
    "\n",
    "print(\"LAST INDEX: \", cut_off_indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "third-handling",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 4 1 2 3]\n",
      "[0 4 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "chopped_indices = sorted_idx[0:cut_off_indx+1]\n",
    "\n",
    "print(sorted_idx)\n",
    "print(chopped_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-profit",
   "metadata": {},
   "source": [
    "<h3><u>SELECTED TOP COLUMNS</u></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "expressed-motor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean_sea_level_pressure_pascal', 'surface_pressure_surface_level_pascal', '10_metre_u_wind_component_meters_per_second', '10_metre_v_wind_component_meters_per_second', 'soil_temperature_kelvin']\n",
      "['pressure_pascal']\n"
     ]
    }
   ],
   "source": [
    "candidate_x_columns = list(X.columns)\n",
    "candidate_y_columns = list(Y.columns)\n",
    "\n",
    "print(candidate_x_columns)\n",
    "print(candidate_y_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "political-sight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_sea_level_pressure_pascal',\n",
       " 'soil_temperature_kelvin',\n",
       " 'surface_pressure_surface_level_pascal',\n",
       " '10_metre_u_wind_component_meters_per_second',\n",
       " '10_metre_v_wind_component_meters_per_second']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_x_columns = [candidate_x_columns[i] for i in chopped_indices]\n",
    "selected_x_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-topic",
   "metadata": {},
   "source": [
    "<b><hr /></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-strand",
   "metadata": {},
   "source": [
    "<h1><u><b>TRAINING PHASE #2</b></u></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-boston",
   "metadata": {},
   "source": [
    "<h3><u>AGGREGATE QUERY OVER THE CHOSEN COLUMNS PER GIS-JOIN</u></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fitting-nylon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sustain_collection = sustain_db[query_collection]\\npipeline=[\\n   { \"$project\": { \\'gis_join\\': \\'$gis_join\\', \\'max_specific_humidity\\': \\'$max_specific_humidity\\', \\'max_max_air_temperature\\': \\'$max_max_air_temperature\\', \\'max_min_air_temperature\\': \\'$max_min_air_temperature\\'}},\\n   { \"$group\": { \\'_id\\': \"$gis_join\", \\n\"avg_max_specific_humidity\": { \"$avg\": \"$max_specific_humidity\" },\\n\"avg_max_max_air_temperature\": { \"$avg\": \"$max_max_air_temperature\" },\\n\"avg_max_min_air_temperature\": { \"$avg\": \"$max_min_air_temperature\" }\\n  } }\\n]\\ncur = sustain_collection.aggregate(pipeline)\\n\\nresults = list(cur)\\nlen(results)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''sustain_collection = sustain_db[query_collection]\n",
    "pipeline=[\n",
    "   { \"$project\": { 'gis_join': '$gis_join', 'max_specific_humidity': '$max_specific_humidity', 'max_max_air_temperature': '$max_max_air_temperature', 'max_min_air_temperature': '$max_min_air_temperature'}},\n",
    "   { \"$group\": { '_id': \"$gis_join\", \n",
    "\"avg_max_specific_humidity\": { \"$avg\": \"$max_specific_humidity\" },\n",
    "\"avg_max_max_air_temperature\": { \"$avg\": \"$max_max_air_temperature\" },\n",
    "\"avg_max_min_air_temperature\": { \"$avg\": \"$max_min_air_temperature\" }\n",
    "  } }\n",
    "]\n",
    "cur = sustain_collection.aggregate(pipeline)\n",
    "\n",
    "results = list(cur)\n",
    "len(results)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "known-situation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean_sea_level_pressure_pascal', 'soil_temperature_kelvin', 'surface_pressure_surface_level_pascal', '10_metre_u_wind_component_meters_per_second', '10_metre_v_wind_component_meters_per_second', 'pressure_pascal']\n"
     ]
    }
   ],
   "source": [
    "chopped_projection = []\n",
    "chopped_projection.extend(selected_x_columns)\n",
    "chopped_projection.extend(candidate_y_columns)\n",
    "\n",
    "print(chopped_projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "happy-auckland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_chopped_query(chopped_projection, gis_join):\n",
    "    # PROJECTION\n",
    "    proj_d = {}\n",
    "    proj_dict = {'$project': proj_d}\n",
    "    \n",
    "    #GROUP + AGGREGATION\n",
    "    group_d = {}\n",
    "    group_dict = {'$group': group_d}\n",
    "    \n",
    "    full_query=[proj_dict, group_dict]\n",
    "    \n",
    "    # PROJECTION PART\n",
    "    for cp in chopped_projection:\n",
    "        proj_d[cp] = \"$\"+str(cp)\n",
    "    proj_d[gis_join] = \"$\"+str(gis_join)\n",
    "    \n",
    "    # GROUP PART\n",
    "    group_d['_id'] = \"$\"+str(gis_join)\n",
    "    for cp in chopped_projection:\n",
    "        inner_dict = {}\n",
    "        inner_dict[\"$avg\"] = \"$\"+str(cp)\n",
    "        group_d[cp] = inner_dict\n",
    "    \n",
    "    return full_query\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "inclusive-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_pipeline = construct_chopped_query(chopped_projection, query_fild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "recreational-visiting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3065\n"
     ]
    }
   ],
   "source": [
    "sustain_collection = sustain_db[query_collection]\n",
    "cur = sustain_collection.aggregate(agg_pipeline)\n",
    "agg_results = list(cur)\n",
    "\n",
    "print(len(agg_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "promising-rocket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 'G2800830',\n",
       " 'mean_sea_level_pressure_pascal': 102234.0659090909,\n",
       " 'soil_temperature_kelvin': 277.1112470222242,\n",
       " 'surface_pressure_surface_level_pascal': 101758.07575757576,\n",
       " '10_metre_u_wind_component_meters_per_second': -0.12724994457129277,\n",
       " '10_metre_v_wind_component_meters_per_second': 0.3196709069338712,\n",
       " 'pressure_pascal': 22627.514105132133}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-water",
   "metadata": {},
   "source": [
    "<h3><u>DATA STAGING FOR PHASE 2</u></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "advisory-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase2_df = pd.DataFrame(agg_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "suburban-bidding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_sea_level_pressure_pascal',\n",
       " 'soil_temperature_kelvin',\n",
       " 'surface_pressure_surface_level_pascal',\n",
       " '10_metre_u_wind_component_meters_per_second',\n",
       " '10_metre_v_wind_component_meters_per_second',\n",
       " 'pressure_pascal']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chopped_projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "finnish-spank",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_sea_level_pressure_pascal</th>\n",
       "      <th>soil_temperature_kelvin</th>\n",
       "      <th>surface_pressure_surface_level_pascal</th>\n",
       "      <th>10_metre_u_wind_component_meters_per_second</th>\n",
       "      <th>10_metre_v_wind_component_meters_per_second</th>\n",
       "      <th>pressure_pascal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102234.065909</td>\n",
       "      <td>277.111247</td>\n",
       "      <td>101758.075758</td>\n",
       "      <td>-0.127250</td>\n",
       "      <td>0.319671</td>\n",
       "      <td>22627.514105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102246.208333</td>\n",
       "      <td>275.947863</td>\n",
       "      <td>100803.669823</td>\n",
       "      <td>-0.212209</td>\n",
       "      <td>0.086574</td>\n",
       "      <td>23359.711075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102276.465909</td>\n",
       "      <td>274.152724</td>\n",
       "      <td>99848.284091</td>\n",
       "      <td>0.176917</td>\n",
       "      <td>0.150258</td>\n",
       "      <td>23679.786832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101970.238444</td>\n",
       "      <td>274.115271</td>\n",
       "      <td>80418.955829</td>\n",
       "      <td>2.531348</td>\n",
       "      <td>-0.692039</td>\n",
       "      <td>23128.271681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102247.914983</td>\n",
       "      <td>277.273358</td>\n",
       "      <td>100544.394781</td>\n",
       "      <td>0.118152</td>\n",
       "      <td>0.214494</td>\n",
       "      <td>20937.194240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>102022.247934</td>\n",
       "      <td>276.984723</td>\n",
       "      <td>101871.529614</td>\n",
       "      <td>1.275100</td>\n",
       "      <td>0.172684</td>\n",
       "      <td>22423.450744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3061</th>\n",
       "      <td>101974.813740</td>\n",
       "      <td>268.399047</td>\n",
       "      <td>95431.540076</td>\n",
       "      <td>0.476142</td>\n",
       "      <td>1.340470</td>\n",
       "      <td>22165.048730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062</th>\n",
       "      <td>100713.001193</td>\n",
       "      <td>280.044527</td>\n",
       "      <td>95611.141937</td>\n",
       "      <td>0.258859</td>\n",
       "      <td>6.306155</td>\n",
       "      <td>24948.541097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063</th>\n",
       "      <td>102163.510101</td>\n",
       "      <td>279.646758</td>\n",
       "      <td>100528.098485</td>\n",
       "      <td>-0.114529</td>\n",
       "      <td>0.993724</td>\n",
       "      <td>22426.756529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3064</th>\n",
       "      <td>101587.806870</td>\n",
       "      <td>273.447115</td>\n",
       "      <td>83302.704071</td>\n",
       "      <td>0.445011</td>\n",
       "      <td>2.772770</td>\n",
       "      <td>23349.425321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3065 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_sea_level_pressure_pascal  soil_temperature_kelvin  \\\n",
       "0                      102234.065909               277.111247   \n",
       "1                      102246.208333               275.947863   \n",
       "2                      102276.465909               274.152724   \n",
       "3                      101970.238444               274.115271   \n",
       "4                      102247.914983               277.273358   \n",
       "...                              ...                      ...   \n",
       "3060                   102022.247934               276.984723   \n",
       "3061                   101974.813740               268.399047   \n",
       "3062                   100713.001193               280.044527   \n",
       "3063                   102163.510101               279.646758   \n",
       "3064                   101587.806870               273.447115   \n",
       "\n",
       "      surface_pressure_surface_level_pascal  \\\n",
       "0                             101758.075758   \n",
       "1                             100803.669823   \n",
       "2                              99848.284091   \n",
       "3                              80418.955829   \n",
       "4                             100544.394781   \n",
       "...                                     ...   \n",
       "3060                          101871.529614   \n",
       "3061                           95431.540076   \n",
       "3062                           95611.141937   \n",
       "3063                          100528.098485   \n",
       "3064                           83302.704071   \n",
       "\n",
       "      10_metre_u_wind_component_meters_per_second  \\\n",
       "0                                       -0.127250   \n",
       "1                                       -0.212209   \n",
       "2                                        0.176917   \n",
       "3                                        2.531348   \n",
       "4                                        0.118152   \n",
       "...                                           ...   \n",
       "3060                                     1.275100   \n",
       "3061                                     0.476142   \n",
       "3062                                     0.258859   \n",
       "3063                                    -0.114529   \n",
       "3064                                     0.445011   \n",
       "\n",
       "      10_metre_v_wind_component_meters_per_second  pressure_pascal  \n",
       "0                                        0.319671     22627.514105  \n",
       "1                                        0.086574     23359.711075  \n",
       "2                                        0.150258     23679.786832  \n",
       "3                                       -0.692039     23128.271681  \n",
       "4                                        0.214494     20937.194240  \n",
       "...                                           ...              ...  \n",
       "3060                                     0.172684     22423.450744  \n",
       "3061                                     1.340470     22165.048730  \n",
       "3062                                     6.306155     24948.541097  \n",
       "3063                                     0.993724     22426.756529  \n",
       "3064                                     2.772770     23349.425321  \n",
       "\n",
       "[3065 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_importance = phase2_df.loc[:, chopped_projection]\n",
    "df_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-bullet",
   "metadata": {},
   "source": [
    "<h3><u>K-MEANS CLUSTERING</u></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bridal-cartridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_clusters = int(sqrt(len(agg_results)))\n",
    "\n",
    "num_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "superior-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "copyrighted-behavior",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.02094183e+05  2.71126635e+02  9.83491463e+04  1.04481658e+00\n",
      "   9.65980195e-01  2.30599910e+04]\n",
      " [ 1.01624498e+05  2.72477867e+02  8.55800281e+04 -2.27342203e-03\n",
      "   2.26294882e+00  2.33334610e+04]\n",
      " [ 1.02129662e+05  2.80528724e+02  1.00577855e+05  6.01700489e-01\n",
      "   4.76282264e-03  1.75947082e+04]\n",
      " [ 1.02048884e+05  2.70189431e+02  7.78161447e+04  1.35862908e+00\n",
      "   1.06653056e+00  2.28694485e+04]\n",
      " [ 1.01818074e+05  2.73614308e+02  9.03345125e+04  1.44048031e+00\n",
      "   7.66892354e-01  2.23091430e+04]\n",
      " [ 1.02199261e+05  2.72085537e+02  9.97048499e+04  5.92306883e-01\n",
      "   6.68757893e-01  2.28456529e+04]\n",
      " [ 1.01910817e+05  2.72107941e+02  9.44087428e+04  7.09198887e-01\n",
      "   9.43789965e-01  2.23015163e+04]\n",
      " [ 1.02208595e+05  2.85037018e+02  1.02048883e+05  6.67016988e-01\n",
      "  -6.90333953e-01  1.08856458e+04]\n",
      " [ 1.02168170e+05  2.78705884e+02  1.01207482e+05  1.66612243e-01\n",
      "   3.75058473e-01  2.08707957e+04]\n",
      " [ 1.02148912e+05  2.69303647e+02  7.28173794e+04  1.55507437e+00\n",
      "   5.16517791e-01  2.27455298e+04]\n",
      " [ 1.01933206e+05  2.72069736e+02  8.22443487e+04  8.83133760e-01\n",
      "   1.11881328e+00  2.27579132e+04]\n",
      " [ 1.01936653e+05  2.71883916e+02  9.57310367e+04  1.51914709e+00\n",
      "   5.19625371e-01  2.40723614e+04]\n",
      " [ 1.01909546e+05  2.73926570e+02  1.01594420e+05  1.76096920e+00\n",
      "  -1.06904477e+00  2.46619434e+04]\n",
      " [ 1.02018365e+05  2.70883950e+02  9.67961514e+04  3.60110172e-01\n",
      "   9.30854203e-01  2.20588795e+04]\n",
      " [ 1.01618329e+05  2.73562807e+02  9.16153208e+04  2.76792182e-01\n",
      "   1.15100786e+00  2.39145546e+04]\n",
      " [ 1.02214502e+05  2.82166647e+02  1.01952685e+05  8.06229467e-01\n",
      "  -5.62202038e-02  1.39512786e+04]\n",
      " [ 1.00957037e+05  2.75983495e+02  9.81586675e+04  2.21290642e-02\n",
      "   2.04436598e+00  2.53195397e+04]\n",
      " [ 1.02107951e+05  2.78259895e+02  1.00516218e+05  4.41202726e-02\n",
      "   6.95614597e-01  2.21835432e+04]\n",
      " [ 1.01655937e+05  2.83326566e+02  9.37209681e+04  1.71113767e-01\n",
      "   5.94791378e-01  1.78977233e+04]\n",
      " [ 1.02209476e+05  2.72049210e+02  9.91531814e+04  1.08704076e+00\n",
      "   5.56027098e-01  2.35170066e+04]\n",
      " [ 1.02181583e+05  2.80499005e+02  1.01457019e+05  6.64089256e-01\n",
      "  -4.62629607e-02  1.66064416e+04]\n",
      " [ 1.02121683e+05  2.72450491e+02  9.83795665e+04  2.91701215e-01\n",
      "   8.31872149e-01  2.22779465e+04]\n",
      " [ 1.02153966e+05  2.76517670e+02  1.01462846e+05  2.06409497e-01\n",
      "   3.25493493e-01  2.30233237e+04]\n",
      " [ 1.01735741e+05  2.72338345e+02  8.37757211e+04  1.00585454e+00\n",
      "   1.55229753e+00  2.28732687e+04]\n",
      " [ 1.01503928e+05  2.74534802e+02  8.94070042e+04  6.86595742e-01\n",
      "   1.64366187e+00  2.33593580e+04]\n",
      " [ 1.02052960e+05  2.71456311e+02  9.70498292e+04  1.70165957e+00\n",
      "  -1.11950561e-02  2.41637481e+04]\n",
      " [ 1.01886714e+05  2.73786866e+02  9.30921230e+04  1.01762190e+00\n",
      "   9.32540217e-01  2.24081688e+04]\n",
      " [ 1.02178642e+05  2.79403031e+02  1.00885683e+05  3.08380492e-01\n",
      "   1.28757650e-01  1.94455567e+04]\n",
      " [ 1.01808817e+05  2.74511692e+02  8.82805939e+04  1.32988213e+00\n",
      "   6.01239492e-01  2.21595955e+04]\n",
      " [ 1.00882435e+05  2.77273685e+02  9.36838043e+04 -7.69942891e-01\n",
      "   3.03027937e+00  2.43076016e+04]\n",
      " [ 1.02090943e+05  2.70149688e+02  6.88474728e+04  1.39402478e+00\n",
      "   1.80984905e-01  2.27619299e+04]\n",
      " [ 1.01748446e+05  2.69339149e+02  9.66320101e+04  1.83168397e+00\n",
      "  -3.09744272e-01  2.60532736e+04]\n",
      " [ 9.91390739e+04  2.73635736e+02  9.48403409e+04 -2.45951181e+00\n",
      "   1.70341720e+00  2.69355384e+04]\n",
      " [ 1.01768372e+05  2.73849460e+02  8.66069357e+04  1.17222832e+00\n",
      "   6.88441265e-01  2.24969816e+04]\n",
      " [ 1.01855139e+05  2.72523071e+02  1.00418436e+05  1.60111409e+00\n",
      "  -6.64164063e-01  2.46794271e+04]\n",
      " [ 1.02054817e+05  2.71081090e+02  9.76273873e+04  3.90937599e-01\n",
      "   1.10350026e+00  2.24396875e+04]\n",
      " [ 1.01941289e+05  2.71485671e+02  9.56837548e+04  6.32728701e-01\n",
      "   1.08223646e+00  2.22899169e+04]\n",
      " [ 1.02231676e+05  2.74020112e+02  1.00507610e+05  1.00962604e-01\n",
      "   2.88275487e-01  2.31981208e+04]\n",
      " [ 1.02072099e+05  2.69946033e+02  7.60521947e+04  7.97324455e-01\n",
      "   9.52888779e-01  2.27747245e+04]\n",
      " [ 1.01635692e+05  2.69574942e+02  1.00412578e+05  1.41424682e+00\n",
      "  -1.16280017e+00  2.62334885e+04]\n",
      " [ 1.02062382e+05  2.78290954e+02  9.93316010e+04  7.13048600e-01\n",
      "   2.50805588e-01  2.10921506e+04]\n",
      " [ 1.02170043e+05  2.80006007e+02  1.01872687e+05 -1.52356718e-01\n",
      "   1.36141227e-01  1.98417368e+04]\n",
      " [ 1.02186061e+05  2.80814291e+02  1.01873851e+05 -3.14831319e-01\n",
      "  -5.18561367e-02  1.83112490e+04]\n",
      " [ 1.01805654e+05  2.72878921e+02  9.17442110e+04  1.21982843e+00\n",
      "   9.76750928e-01  2.23584329e+04]\n",
      " [ 1.01873442e+05  2.71230190e+02  9.91574419e+04  2.09016374e+00\n",
      "  -2.45021340e-01  2.45183799e+04]\n",
      " [ 1.01965610e+05  2.70812482e+02  8.10038372e+04  6.61455640e-01\n",
      "   1.28812173e+00  2.29420430e+04]\n",
      " [ 1.02199993e+05  2.80702766e+02  1.01553034e+05  9.87093795e-01\n",
      "  -1.59037406e-02  1.53966227e+04]\n",
      " [ 1.02160765e+05  2.78239988e+02  1.01556456e+05  2.61414135e-01\n",
      "   3.86128982e-01  2.18380291e+04]\n",
      " [ 1.02132015e+05  2.71857105e+02  9.81520812e+04  1.44759440e+00\n",
      "   4.45534729e-01  2.38979870e+04]\n",
      " [ 1.01942367e+05  2.71858664e+02  9.68984189e+04  7.24768858e-01\n",
      "   1.42769144e+00  2.30095504e+04]\n",
      " [ 1.01560297e+05  2.83740281e+02  9.62021383e+04 -2.02142858e-01\n",
      "   1.35415402e+00  1.89632709e+04]\n",
      " [ 1.02185087e+05  2.71412916e+02  9.36666362e+04  1.98381147e+00\n",
      "  -2.32772010e-01  2.42614421e+04]\n",
      " [ 1.02128581e+05  2.69928530e+02  7.94034374e+04  2.60703559e-01\n",
      "   1.17700816e+00  2.29704913e+04]\n",
      " [ 1.02144385e+05  2.78946003e+02  9.97705528e+04  6.23312190e-01\n",
      "  -1.26881502e-01  1.97611932e+04]\n",
      " [ 1.02151461e+05  2.72700246e+02  9.91072296e+04  5.03040896e-01\n",
      "   7.82321276e-01  2.25962563e+04]]\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=num_clusters).fit(df_importance)\n",
    "centroids = kmeans.cluster_centers_\n",
    "print(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "comparable-young",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      gis_join cluster_id     distance\n",
      "0     G2800830         22   500.242358\n",
      "1     G2800710         37   337.606283\n",
      "2     G4701690         19   717.048229\n",
      "3     G3500570         45   613.846118\n",
      "4     G2800990          8   671.159339\n",
      "...        ...        ...          ...\n",
      "3060  G3700150         47   679.101926\n",
      "3061  G4600110         36   283.439265\n",
      "3062  G4100150         11  1509.798680\n",
      "3063  G4804990         17   249.765275\n",
      "3064  G3200310         23   687.283010\n",
      "\n",
      "[3065 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "df_ultimate = pd.DataFrame(columns=[\"gis_join\", \"cluster_id\", \"distance\"])\n",
    "\n",
    "\n",
    "\n",
    "for index, row in phase2_df.iterrows():\n",
    "    input_x = row[chopped_projection]\n",
    "    gis_join = row['_id']\n",
    "    #print(input_x, gis_join)\n",
    "    closest, d = pairwise_distances_argmin_min([np.array(input_x)], centroids)\n",
    "    df_ultimate.loc[index] = [gis_join, closest[0], d[0]]\n",
    "    \n",
    "print(df_ultimate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "likely-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ultimate.to_csv(\"~/ucc-21/clusters-noaa.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
